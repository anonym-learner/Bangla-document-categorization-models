{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_classifier_LSTM_tfidf.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jrmHuWQszBVF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1590220464926,"user_tz":-360,"elapsed":9502,"user":{"displayName":"Anonymous Learner","photoUrl":"","userId":"07578854066066276758"}},"outputId":"18bf19bb-5c25-4d6a-ea54-30d8643e4020"},"source":["import io\n","import os\n","import re\n","import keras\n","import tensorflow as tf\n","import numpy as np # used for handling numbers\n","import pandas as pd # used for handling the dataset\n","df= pd.read_csv('drive/My Drive/Colab Notebooks/dataset/labeled_outs.txt',delimiter=\",\",header=None)\n","kw=pd.read_csv('drive/My Drive/Colab Notebooks/dataset/frequent.txt',header=None)\n","# Dataset is now stored in a Pandas Dataframe"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5H-5E9dm3ZYe","colab_type":"code","colab":{}},"source":["df.columns=['label','text']\n","df.text=df.text.astype(str)\n","df.label=df.label.astype(str)\n","df=df.sample(frac=1)\n","docs=df['text'].values\n","labels=df['label'].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1kg7Wk0xfGq","colab_type":"code","colab":{}},"source":["\n","from sklearn.feature_extraction.text import CountVectorizer\n","input_dim=5000\n","count_vect = CountVectorizer(max_features = input_dim)\n","X_train_counts = count_vect.fit_transform(docs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vcCDEW77sBi","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","\n","tfidf_transformer = TfidfTransformer()\n","X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","X_train_tfidf.shape\n","X_train_tfidf = X_train_tfidf.toarray()\n","X_train_tfidf = np.reshape(X_train_tfidf, (X_train_tfidf.shape[0],10, -1))\n","print(X_train_tfidf.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RO-zHTSBHpw","colab_type":"code","colab":{}},"source":["\n","kw.columns=['words']\n","dfreq={}\n","for k in kw['words']:\n","  dfreq[k]=0\n","print(len(dfreq))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGlwd8GMSs1p","colab_type":"code","colab":{}},"source":["for d in docs:\n","  words=re.split('[\\s]',d)\n","  words=np.unique(words)\n","  for w in words:\n","    if w in dfreq:\n","      dfreq[w]=dfreq[w]+1\n","\n","tf_idf = []\n","for d in docs:\n","  words=re.split('[\\s]',d)\n","  N=len(words)\n","  tfreq={}\n","  for w in words:\n","    if w in tfreq:\n","      tfreq[w]=tfreq[w]+1\n","    else:\n","      tfreq[w]=1\n","  temp=[]\n","  for w in dfreq:\n","    if w in tfreq:\n","      tf=tfreq[w]*1.0/N\n","      idf=np.log(len(docs)*1.0/dfreq[w])\n","      temp.append(tf*idf)\n","    else:\n","      temp.append(0.0)\n","  tf_idf.append(temp)\n","\n","tf_idf = np.array(tf_idf)\n","input_dim=len(tf_idf[0])\n","print(input_dim)\n","tf_idf = np.reshape(tf_idf, (tf_idf.shape[0],1,-1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWSLyHOec88f","colab_type":"code","colab":{}},"source":["\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","print(labels)\n","# encode class values as integers\n","encoder = LabelEncoder()\n","encoder.fit(labels)\n","encoded_Y = encoder.transform(labels)\n","# convert integers to dummy variables (i.e. one hot encoded)\n","dummy_y = np_utils.to_categorical(encoded_Y)\n","print(dummy_y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNV6YWuWiuqZ","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(tf_idf, dummy_y, test_size=0.18)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_muHxENijKeD","colab_type":"code","colab":{}},"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wk4-2N4bCXlI","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","\n","model = Sequential()\n","model.add(LSTM(2048, input_shape=(X_train.shape[1],X_train.shape[2]),return_sequences=True,dropout=0.5,recurrent_dropout=0.3))\n","model.add(BatchNormalization())\n","model.add(LSTM(1024,return_sequences=True,dropout=0.4,recurrent_dropout=0.3))\n","model.add(BatchNormalization())\n","model.add(LSTM(512,return_sequences=True,dropout=0.4,recurrent_dropout=0.3))\n","model.add(BatchNormalization())\n","model.add(LSTM(256,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))\n","model.add(LSTM(128,return_sequences=True,dropout=0.3,recurrent_dropout=0.2))\n","model.add(LSTM(64,return_sequences=True,dropout=0.2,recurrent_dropout=0.1))\n","model.add(LSTM(32,return_sequences=True))\n","model.add(LSTM(16))\n","model.add(Dense(8, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0WqhrRO5Cdkc","colab_type":"code","colab":{}},"source":["\n","model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=['acc'])\n","# summarize the model\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVZ-OArxCftu","colab_type":"code","colab":{}},"source":["history = model.fit(X_train, y_train, epochs=25,batch_size=256,shuffle=False, verbose=1,validation_split=0.1)\n","#model.save_weights('./checkpoints/text_classifier_rnn_tfidf')\n","!mkdir -p saved_model\n","model.save('saved_model/text_classifier_rnn_tfidf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2ADuRJWAkYz","colab_type":"code","colab":{}},"source":["#model.load_weights('./checkpoints/text_classifier_rnn_tfidf')\n","new_model = tf.keras.models.load_model('saved_model/text_classifier_rnn_tfidf')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2qLIzmWvnEm","colab_type":"code","colab":{}},"source":["results = model.evaluate(X_test, y_test)\n","print(results)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Xw6vRrx72k8","colab_type":"code","colab":{}},"source":["y_pred=model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tr07OB7wvsL0","colab_type":"code","colab":{}},"source":["\"\"\"\n","import numpy as np\n","array1=[[ 0,  1,  2,  3,  4],\n","       [ 0,  1,  2,  3,  4],\n","       [5, 6, 7, 1, 0],\n","       [5, 6, 7, 1, 0]]\n","array2=[[ 5, 6, 7, 1, 0],\n","       [ 0,  1,  2,  3,  4],\n","       [0,  1,  2,  3,  4],\n","       [5, 6, 7, 1, 0]]\n","\"\"\"\n","no_cat=len(y_test[0])\n","conf_mat=np.zeros(no_cat*no_cat).reshape(no_cat,no_cat)\n","test_size=len(y_test)\n","print(conf_mat.shape)\n","for i in range(test_size):\n","  y_t=y_test[i]\n","  y_p=y_pred[i]\n","  class_t=np.where(y_t == np.amax(y_t))\n","  class_t=class_t[0][0]\n","  class_p=np.where(y_p == np.amax(y_p))\n","  class_p=class_p[0][0]\n","  conf_mat[class_t][class_p]=conf_mat[class_t][class_p]+1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmoV23mdvupX","colab_type":"code","colab":{}},"source":["tp=np.zeros(no_cat)\n","fp=np.zeros(no_cat)\n","tn=np.zeros(no_cat)\n","fn=np.zeros(no_cat)\n","\n","prec=np.zeros(no_cat)\n","rec=np.zeros(no_cat)\n","f_score=np.zeros(no_cat)\n","\n","for i in range(no_cat):\n","  for j in range(no_cat):\n","    if i==j:\n","      tp[i]=conf_mat[i][j]\n","    if i!= j:\n","      fp[i] = fp[i]+conf_mat[j][i]\n","      fn[i] = fn[i]+conf_mat[i][j]\n","    for k in range(no_cat):\n","      if i!=k & j!=k:\n","        tn[i]=tn[i]+conf_mat[j][k]\n","\n","for i in range(no_cat):\n","    prec[i] = tp[i] * 100.0 / (tp[i] + fp[i])\n","    rec[i] = tp[i] * 100.0 / (tp[i] + fn[i])\n","    f_score[i] = 2 * prec[i] * rec[i] / (prec[i] + rec[i])\n","\n","print(np.average(prec))\n","print(np.average(rec))\n","print(np.average(f_score))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"56DIb09zf9v_","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}